{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from projio.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# projio\n",
    "\n",
    "> Centralized path management for Python packages with Lightning awareness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Every data science project eventually becomes a mess of hardcoded paths:\n",
    "\n",
    "```python\n",
    "# Scattered across your codebase...\n",
    "data = pd.read_csv(\"/home/user/projects/myproject/data/raw/sales.csv\")\n",
    "model.save(\"/home/user/projects/myproject/outputs/models/best_model.pt\")\n",
    "writer = SummaryWriter(\"/home/user/projects/myproject/runs/exp_001\")\n",
    "results.to_csv(f\"/home/user/projects/myproject/outputs/{datetime.now():%Y%m%d}_results.csv\")\n",
    "```\n",
    "\n",
    "This leads to:\n",
    "- **Brittle code** that breaks when you move directories or share with collaborators\n",
    "- **Inconsistent organization** across experiments and team members  \n",
    "- **Lost outputs** when you forget which script created which file\n",
    "- **Overwritten results** when you re-run without changing output paths\n",
    "- **Manual directory creation** scattered throughout your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## The Solution\n",
    "\n",
    "`projio` centralizes all path management in one place:\n",
    "\n",
    "```python\n",
    "from projio import PIO\n",
    "\n",
    "# Configure once at startup\n",
    "PIO.root = \"./my_project\"\n",
    "\n",
    "# Use everywhere - paths are consistent, directories auto-created\n",
    "data = pd.read_csv(PIO.data_dir / \"raw\" / \"sales.csv\")\n",
    "model.save(PIO.checkpoint_path(\"best_model\", run=\"exp_001\"))\n",
    "writer = SummaryWriter(PIO.tensorboard_run(run=\"exp_001\"))\n",
    "results.to_csv(PIO.path_for(\"outputs\", \"results\", ext=\".csv\"))  # Auto-datestamped!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```sh\n",
    "pip install projio\n",
    "```\n",
    "\n",
    "Or install from GitHub:\n",
    "\n",
    "```sh\n",
    "pip install git+https://github.com/s01st/project-io.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from projio import ProjectIO, PIO\n",
    "\n",
    "# Create a ProjectIO instance\n",
    "tmp = tempfile.mkdtemp()\n",
    "io = ProjectIO(root=tmp, use_datestamp=False)\n",
    "\n",
    "print(f\"Root: {io.root}\")\n",
    "print(f\"Outputs: {io.outputs}\")\n",
    "print(f\"Cache: {io.cache}\")\n",
    "print(f\"Checkpoints: {io.checkpoints}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Features & Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 1. Root Cascade\n",
    "\n",
    "**The problem:** You have input data in one location and want outputs in another, but most paths should share a common base.\n",
    "\n",
    "**The solution:** Set `root` once and `iroot`/`oroot` follow automatically. Override individually when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple case: everything under one root\n",
    "io = ProjectIO(root=tmp, use_datestamp=False)\n",
    "print(f\"Input root: {io.iroot}\")\n",
    "print(f\"Output root: {io.oroot}\")\n",
    "print(f\"Both follow root: {io.iroot == io.oroot == io.root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced case: separate input/output locations\n",
    "data_dir = tempfile.mkdtemp()\n",
    "results_dir = tempfile.mkdtemp()\n",
    "\n",
    "io = ProjectIO(\n",
    "    root=tmp,\n",
    "    iroot=data_dir,      # Read data from here\n",
    "    oroot=results_dir,   # Write outputs here\n",
    "    use_datestamp=False\n",
    ")\n",
    "\n",
    "print(f\"Data comes from: {io.inputs}\")\n",
    "print(f\"Results go to: {io.outputs}\")\n",
    "print(f\"Config/resources from: {io.root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "**When to use:** \n",
    "- Shared datasets on network storage with local output directories\n",
    "- Read-only input mounts (e.g., in containers)\n",
    "- Separating raw data from generated artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 2. Automatic Datestamps\n",
    "\n",
    "**The problem:** You run an experiment, then run it again next week. The old results are overwritten and lost forever.\n",
    "\n",
    "**The solution:** Automatic date-based organization keeps every run separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "io = ProjectIO(root=tmp, use_datestamp=True, datestamp_in=\"dirs\", auto_create=False)\n",
    "io.datestamp_value = lambda ts=None: \"2024_03_15\"  # Mock for demo\n",
    "\n",
    "# Paths automatically include today's date\n",
    "print(f\"Output: {io.path_for('outputs', 'results', ext='.csv')}\")\n",
    "print(f\"Checkpoint: {io.checkpoint_path('model', run='baseline')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different placement options\n",
    "from pathlib import Path\n",
    "for placement in [\"dirs\", \"files\", \"both\"]:\n",
    "    io = ProjectIO(root=tmp, use_datestamp=True, datestamp_in=placement, auto_create=False)\n",
    "    io.datestamp_value = lambda ts=None: \"2024_03_15\"\n",
    "    path = io.path_for('outputs', 'results', ext='.csv')\n",
    "    # Show path relative to root (resolve symlinks for macOS compatibility)\n",
    "    rel = path.relative_to(Path(tmp).resolve())\n",
    "    print(f\"{placement:5} -> {rel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "**When to use:**\n",
    "- Long-running projects with multiple experiment runs\n",
    "- When you need to compare results across days/weeks\n",
    "- Audit trails for regulatory compliance\n",
    "- Any time you've ever overwritten important results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 3. Unified Path Building\n",
    "\n",
    "**The problem:** Different parts of your codebase use different conventions for organizing files.\n",
    "\n",
    "**The solution:** One consistent API for all path types with automatic directory creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "io = ProjectIO(root=tmp, use_datestamp=False, auto_create=True)\n",
    "\n",
    "# All path types use the same pattern\n",
    "print(\"Path types:\")\n",
    "print(f\"  outputs: {io.path_for('outputs', 'analysis', ext='.csv')}\")\n",
    "print(f\"  cache:   {io.path_for('cache', 'preprocessed', ext='.pkl')}\")\n",
    "print(f\"  logs:    {io.path_for('logs', 'training', ext='.log')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subdirectories are easy\n",
    "path = io.path_for('outputs', 'model', subdir=['experiment_1', 'fold_3'], ext='.pt')\n",
    "print(f\"Nested path: {path}\")\n",
    "print(f\"Directory created: {path.parent.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "**When to use:**\n",
    "- Any project with multiple output types\n",
    "- When you want directories created automatically\n",
    "- Team projects needing consistent organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 4. Lightning Integration\n",
    "\n",
    "**The problem:** PyTorch Lightning projects need checkpoint directories, TensorBoard logs, and training logs - all organized consistently.\n",
    "\n",
    "**The solution:** Built-in support for Lightning artifacts with dedicated path methods and callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "io = ProjectIO(root=tmp, use_datestamp=False)\n",
    "\n",
    "# Lightning-specific paths\n",
    "print(f\"Lightning root: {io.lightning_root}\")\n",
    "print(f\"Checkpoints: {io.checkpoints}\")\n",
    "print(f\"TensorBoard: {io.tensorboard}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organized by run name\n",
    "print(f\"\\nRun-specific paths:\")\n",
    "print(f\"  Checkpoint: {io.checkpoint_path('epoch_10', run='baseline_v2')}\")\n",
    "print(f\"  TensorBoard: {io.tensorboard_run(run='baseline_v2')}\")\n",
    "print(f\"  Log: {io.log_path('metrics', run='baseline_v2')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use callbacks for seamless integration\n",
    "from projio.callbacks import IOCheckpointCallback, IOLogCallback\n",
    "\n",
    "ckpt_cb = IOCheckpointCallback(io=io, run=\"experiment_1\")\n",
    "log_cb = IOLogCallback(io=io, run=\"experiment_1\")\n",
    "\n",
    "print(f\"Checkpoint callback dir: {ckpt_cb.checkpoint_dir}\")\n",
    "print(f\"Log callback dir: {log_cb.log_dir}\")\n",
    "\n",
    "# In your training script:\n",
    "# trainer = Trainer(callbacks=[ckpt_cb, log_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "**When to use:**\n",
    "- Any PyTorch Lightning project\n",
    "- When you need consistent checkpoint/log organization\n",
    "- Multi-run experiments with TensorBoard comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 5. Templates for Multi-File Datasets\n",
    "\n",
    "**The problem:** Some datasets consist of multiple related files (e.g., 10X Genomics output has `matrix.mtx`, `barcodes.tsv`, `features.tsv`). Managing these paths individually is tedious.\n",
    "\n",
    "**The solution:** Templates define file patterns that resolve to multiple paths at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "io = ProjectIO(root=tmp, use_datestamp=False, auto_create=False)\n",
    "\n",
    "# Built-in template for single-cell data\n",
    "paths = io.template_path(\"filtered_matrix\")\n",
    "print(\"10X Genomics filtered matrix files:\")\n",
    "for name, path in paths.items():\n",
    "    print(f\"  {name}: {path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register your own templates\n",
    "from projio.funcs import TemplateSpec\n",
    "\n",
    "# Template for a trained model package\n",
    "model_template = TemplateSpec(\n",
    "    name=\"trained_model\",\n",
    "    base=\"outputs\",\n",
    "    pattern={\n",
    "        \"weights\": \"model/weights.pt\",\n",
    "        \"config\": \"model/config.json\",\n",
    "        \"tokenizer\": \"model/tokenizer.json\",\n",
    "        \"metrics\": \"model/eval_metrics.json\"\n",
    "    }\n",
    ")\n",
    "io.register_template(model_template)\n",
    "\n",
    "paths = io.template_path(\"trained_model\")\n",
    "print(\"\\nTrained model files:\")\n",
    "for name, path in paths.items():\n",
    "    # Show path relative to root (resolve symlinks for macOS compatibility)\n",
    "    rel = path.relative_to(Path(tmp).resolve())\n",
    "    print(f\"  {name}: {rel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "**When to use:**\n",
    "- Bioinformatics (10X, FASTQ pairs, BAM+BAI)\n",
    "- ML model artifacts (weights, config, tokenizer)\n",
    "- Any multi-file data format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## 6. Producer Tracking\n",
    "\n",
    "**The problem:** You find an output file but can't remember which script created it or when.\n",
    "\n",
    "**The solution:** Track which scripts produce which files for full reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "io = ProjectIO(root=tmp, use_datestamp=False)\n",
    "\n",
    "# Track what this script produces\n",
    "output_file = io.path_for('outputs', 'processed_data', ext='.parquet')\n",
    "io.track_producer(\n",
    "    target=output_file,\n",
    "    producer=Path('preprocess.py'),\n",
    "    kind='data'\n",
    ")\n",
    "\n",
    "model_file = io.path_for('outputs', 'model', ext='.pt')\n",
    "io.track_producer(\n",
    "    target=model_file,\n",
    "    producer=Path('train.py'),\n",
    "    kind='model'\n",
    ")\n",
    "\n",
    "# Later, find out what produced a file\n",
    "print(\"Who produced the model?\")\n",
    "for record in io.producers_of(model_file):\n",
    "    print(f\"  {record.producer.name} ({record.kind})\")\n",
    "\n",
    "# Or find all outputs from a script\n",
    "print(\"\\nWhat does train.py produce?\")\n",
    "for record in io.outputs_of(Path('train.py')):\n",
    "    print(f\"  {record.target.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "**When to use:**\n",
    "- Complex pipelines with many intermediate outputs\n",
    "- Debugging data lineage issues\n",
    "- Reproducibility requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## 7. Dry-Run Mode\n",
    "\n",
    "**The problem:** You want to preview what paths will be created without actually touching the filesystem.\n",
    "\n",
    "**The solution:** Dry-run mode returns paths but doesn't create directories or write files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_tmp = tempfile.mkdtemp()\n",
    "io = ProjectIO(root=dry_tmp, dry_run=True)\n",
    "\n",
    "# Get paths without creating anything\n",
    "checkpoint = io.checkpoint_path('model', run='test')\n",
    "output = io.path_for('outputs', 'results', ext='.csv')\n",
    "\n",
    "print(f\"Would create checkpoint: {checkpoint}\")\n",
    "print(f\"Would create output: {output}\")\n",
    "print(f\"\\nDirectories actually created: {any(Path(dry_tmp).iterdir())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "**When to use:**\n",
    "- Testing path configuration before running experiments\n",
    "- CI/CD pipelines that need to validate paths\n",
    "- Debugging path issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## 8. Context Manager for Temporary Overrides\n",
    "\n",
    "**The problem:** You need to temporarily change settings (e.g., disable datestamps for a specific operation) then restore them.\n",
    "\n",
    "**The solution:** The `using()` context manager handles save/restore automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "io = ProjectIO(root=tmp, use_datestamp=True, auto_create=True)\n",
    "\n",
    "print(f\"Normal mode: datestamp={io.use_datestamp}, auto_create={io.auto_create}\")\n",
    "\n",
    "with io.using(use_datestamp=False, auto_create=False):\n",
    "    print(f\"Inside context: datestamp={io.use_datestamp}, auto_create={io.auto_create}\")\n",
    "    # Operations here use the temporary settings\n",
    "\n",
    "print(f\"After context: datestamp={io.use_datestamp}, auto_create={io.auto_create}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "**When to use:**\n",
    "- Writing config files that shouldn't be datestamped\n",
    "- Temporary dry-run for validation\n",
    "- Any setting override that should be scoped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## 9. PIO Singleton for Global Access\n",
    "\n",
    "**The problem:** You need to access paths from anywhere in your codebase without passing an `io` instance everywhere.\n",
    "\n",
    "**The solution:** The `PIO` class provides singleton-style access, similar to `scanpy.settings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from projio import PIO, ProjectIO\n",
    "\n",
    "# Configure once at the start of your application\n",
    "PIO.default = ProjectIO(root=tmp, use_datestamp=False)\n",
    "\n",
    "# Access from anywhere without passing io around\n",
    "print(f\"PIO.root: {PIO.root}\")\n",
    "print(f\"PIO.outputs: {PIO.outputs}\")\n",
    "print(f\"PIO.checkpoints: {PIO.checkpoints}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods work too\n",
    "path = PIO.path_for('cache', 'embeddings', ext='.npy')\n",
    "print(f\"Cache path via PIO: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "**When to use:**\n",
    "- Large codebases where dependency injection is impractical\n",
    "- Interactive notebook workflows\n",
    "- Quick scripts where you want minimal boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "## 10. Directory Tree Visualization\n",
    "\n",
    "**The problem:** You want to quickly see what directory structure has been created.\n",
    "\n",
    "**The solution:** Built-in ASCII tree rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some structure\n",
    "viz_tmp = tempfile.mkdtemp()\n",
    "io = ProjectIO(root=viz_tmp, use_datestamp=False, auto_create=True)\n",
    "\n",
    "# Access paths to create directories\n",
    "_ = io.outputs\n",
    "_ = io.cache  \n",
    "_ = io.checkpoints\n",
    "_ = io.tensorboard\n",
    "_ = io.path_for('outputs', 'exp1', subdir='run_1', ext='.txt')\n",
    "_ = io.path_for('outputs', 'exp1', subdir='run_2', ext='.txt')\n",
    "\n",
    "# Visualize\n",
    "print(io.tree(io.root, max_depth=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Putting It All Together\n",
    "\n",
    "Here's a realistic example combining multiple features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from projio import ProjectIO\n",
    "from projio.callbacks import IOCheckpointCallback, IOLogCallback\n",
    "\n",
    "# Project setup - configure once\n",
    "project_root = tempfile.mkdtemp()\n",
    "io = ProjectIO(\n",
    "    root=project_root,\n",
    "    use_datestamp=True,\n",
    "    datestamp_in=\"dirs\",\n",
    "    auto_create=True\n",
    ")\n",
    "io.datestamp_value = lambda ts=None: \"2024_03_15\"  # Mock for demo\n",
    "\n",
    "run_name = \"baseline_v1\"\n",
    "\n",
    "# Data loading\n",
    "raw_data = io.inputs / \"raw\" / \"dataset.csv\"\n",
    "print(f\"Load data from: {raw_data}\")\n",
    "\n",
    "# Preprocessing with caching\n",
    "cache_path = io.path_for('cache', 'preprocessed', ext='.pkl')\n",
    "print(f\"Cache preprocessed data: {cache_path}\")\n",
    "\n",
    "# Training with Lightning\n",
    "ckpt_cb = IOCheckpointCallback(io=io, run=run_name)\n",
    "log_cb = IOLogCallback(io=io, run=run_name)\n",
    "print(f\"Checkpoints: {ckpt_cb.checkpoint_dir}\")\n",
    "print(f\"TensorBoard: {log_cb.log_dir}\")\n",
    "\n",
    "# Save final results\n",
    "results_path = io.path_for('outputs', 'metrics', subdir=run_name, ext='.json')\n",
    "print(f\"Save results: {results_path}\")\n",
    "\n",
    "# Track what we produced\n",
    "io.track_producer(results_path, Path('train.py'), kind='metrics')\n",
    "\n",
    "# View the structure\n",
    "print(f\"\\nProject structure:\")\n",
    "print(io.tree(io.root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## API Reference\n",
    "\n",
    "### Path Properties\n",
    "\n",
    "| Property | Description |\n",
    "|----------|-------------|\n",
    "| `root` | Shared base path (cascades to iroot/oroot) |\n",
    "| `iroot` / `inputs` | Input/data root |\n",
    "| `oroot` / `outputs` | Output root |\n",
    "| `cache` | Cache directory |\n",
    "| `logs` | Logs directory |\n",
    "| `data_dir` | Data directory under inputs |\n",
    "| `downloads` | Downloads directory under inputs |\n",
    "| `lightning_root` | Root for Lightning artifacts |\n",
    "| `checkpoints` | Checkpoints directory |\n",
    "| `tensorboard` | TensorBoard logs directory |\n",
    "| `resources` | Package resources directory |\n",
    "\n",
    "### Path Builders\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `path_for(kind, name, ...)` | Build path for a given kind |\n",
    "| `checkpoint_path(name, ...)` | Build checkpoint file path |\n",
    "| `log_path(name, ...)` | Build log file path |\n",
    "| `tensorboard_run(run, ...)` | Build TensorBoard run directory |\n",
    "| `resource_path(*parts, ...)` | Get path to a resource file |\n",
    "| `template_path(name, ...)` | Resolve a template to paths |\n",
    "\n",
    "### Configuration\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `root` | cwd | Base directory for all paths |\n",
    "| `iroot` | root | Input/data root (overrides cascade) |\n",
    "| `oroot` | root | Output root (overrides cascade) |\n",
    "| `use_datestamp` | True | Enable automatic datestamps |\n",
    "| `datestamp_format` | `%Y_%m_%d` | strftime format for dates |\n",
    "| `datestamp_in` | `dirs` | Where to add datestamp: dirs/files/both/none |\n",
    "| `auto_create` | True | Automatically create directories |\n",
    "| `dry_run` | False | Preview mode - don't create anything |\n",
    "\n",
    "### Utilities\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| `datestamp_value()` | Get formatted datestamp string |\n",
    "| `parse_datestamp(text)` | Parse datestamp to datetime |\n",
    "| `tree(path, ...)` | Render ASCII directory tree |\n",
    "| `describe()` | Get dict of current configuration |\n",
    "| `using(**overrides)` | Context manager for temp overrides |\n",
    "| `track_producer(...)` | Record file provenance |\n",
    "| `producers_of(path)` | Find what produced a file |\n",
    "| `outputs_of(script)` | Find what a script produces |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tutorials\n",
    "\n",
    "For more detailed examples, see the tutorials:\n",
    "\n",
    "- [Quick Start](../tutorials/01_quickstart.ipynb) - Basic usage and concepts\n",
    "- [Datestamp Handling](../tutorials/02_datestamp.ipynb) - Date-based organization\n",
    "- [Lightning Integration](../tutorials/03_lightning.ipynb) - PyTorch Lightning workflows\n",
    "- [Templates](../tutorials/04_templates.ipynb) - Multi-file dataset patterns\n",
    "- [Advanced Features](../tutorials/05_advanced.ipynb) - Producer tracking, dry-run, gitignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Developer Guide\n",
    "\n",
    "### Development Setup\n",
    "\n",
    "```sh\n",
    "# Clone the repository\n",
    "git clone https://github.com/s01st/project-io.git\n",
    "cd project-io\n",
    "\n",
    "# Install in development mode\n",
    "pip install -e .\n",
    "\n",
    "# Make changes under nbs/ directory\n",
    "# ...\n",
    "\n",
    "# Export and test\n",
    "nbdev_prepare\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
